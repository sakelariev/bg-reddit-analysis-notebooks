# Анализ на /r/bulgaria
Това repository вкючва всичкият код и инструкции за възпроизвеждане от анализа на /r/bulgaria, описан в [този блог пост](https://ivaylo.xyz/posts/2024-04-11-reddit-analysis/).

## Описание
За да извлека данни от Reddit до средата на миналата година ползвах библиотеката `pushshift` , която разчиташе на официалното API на Reddit под повърхността.
През април 2023 година [Reddit наложиха ограничения](https://www.theverge.com/2023/4/18/23688463/reddit-developer-api-terms-change-monetization-ai) за количеството данни, които могат да бъдат изтеглени, използвайки официалното API. Това направи събирането на данни от големи събредити сравнително по-трудно от преди, но за щастие все още има мотивирани хора в Интернет пространството, които са отдадени да правят информацията достъпна и така се появиха няколко проекта, които имат за цел да поддържат достъпа до Reddit данни лесен за изследователи, анализатори и всички други. Един от тези проекти е **[Project Arctic Shift](https://github.com/ArthurHeitmann/arctic_shift).** Всички данни в този анализ (2008-2023 година) са изтеглени с помощта на този проект.

## Инсталиране

За да работите с кода в това repo и да може да възпроизведете всички модели тук, първо трябва да инсталирате някои библиотеки и да изтеглите данните.

1. Клониране на repo
   ```sh
   git clone https://github.com/sakelariev/bg-reddit.git
   ```
2. Създаване на нова среда (conda or virtualenv)
    ```sh
    conda create -n bg-reddit
    ```
3. Активиране на средата
    ```sh
    conda activate bg-reddit
    ```
3. Инсталирайте всички библиотеки.
   ```sh
   pip install -r requirements.txt
   ```
4. Отворете [този торент](https://academictorrents.com/details/56aa49f9653ba545f48df2e33679f014d2829c10) и изберете да изтеглите единствено събредита `/r/bulgaria`

5. След като се изтеглят преместете файловете в папката - `/data/docs`
   
6. Извлечете данните от zst в SQLite.
    ```sh
    python 1_get_data.py
    ```

## Преобразуване на данни и създаване на topic models
След като направите горните стъпки, ще може да работите с Jupyter notebook файловете:
* 2_clean_transform_data.ipynb – изчистване на данните; разделяне на корпуса на два по-малки - английски и български; няколко графики;
* 3_analysis.ipynb – създаването на topic models и работа с тях; повечето графики и код от блог поста;
* 4_prepare_ngrams.ipynb – допълнителен notebook за създаване на n-gram данни;


## License

 CC BY-SA 4.0

